{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar as Biblioteas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import fiona\n",
    "import urllib\n",
    "import shapely\n",
    "import requests\n",
    "import psycopg2\n",
    "import geoalchemy2\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from selenium import webdriver\n",
    "from sqlalchemy import create_engin\n",
    "from selenium.webdriver.common.by import By\n",
    "from pyproj import Proj, transform, Transformer\n",
    "from selenium.webdriver.common.keys import Keys "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções para Extração dos Dados\n",
    "\n",
    "- Pega as categorias, faz a pesquisa, cria os arquivos e junta eles tranformandos em excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['dentista', 'clínica de estética'] # aqui vc coloca as categorias que quer pesquisar \n",
    "\n",
    "for keyword in keywords:\n",
    "\n",
    "\n",
    "    def csv_to_point(non_spatial_data):\n",
    "\n",
    "        #crie o geodataframe e exporte-o como um arquivo de ponto\n",
    "        del non_spatial_data['Tags']\n",
    "        spatial_df = gpd.GeoDataFrame(non_spatial_data, geometry=gpd.points_from_xy(non_spatial_data.Longitude, non_spatial_data.Latitude))\n",
    "        spatial_df.to_csv(\"point_data.csv\")\n",
    "        print(spatial_df)\n",
    "        spatial_df.to_file(\"point_data.shp\")\n",
    "\n",
    "        #cria um arquivo de projeção que corresponde ao local de onde os dados foram retirados\n",
    "        prj = open(\"point_data.prj\", \"w\")\n",
    "        epsg = 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]]'\n",
    "        prj.write(epsg)\n",
    "        prj.close()\n",
    "\n",
    "        return(spatial_df)\n",
    "\n",
    "    def find_locations(search_url, api_key):\n",
    "\n",
    "\n",
    "        #lista de listas para todos os dados\n",
    "        final_data = []\n",
    "\n",
    "        #while loop para solicitar e analisar os arquivos JSON solicitados\n",
    "        while True:\n",
    "            respon = requests.get(search_url)\n",
    "            jj = json.loads(respon.text)\n",
    "            results = jj['results']\n",
    "            #analise todas as informações necessárias\n",
    "            for result in results:\n",
    "                name = result['name']\n",
    "                place_id = result ['place_id']\n",
    "                lat = result['geometry']['location']['lat']\n",
    "                longi = result['geometry']['location']['lng']\n",
    "                rating = result['rating']\n",
    "                types = result['types']\n",
    "                data = [name, place_id, lat, longi, rating, types]\n",
    "                final_data.append(data)\n",
    "            \n",
    "             #se houver uma próxima página, o loop será reiniciado com uma url atualizada\n",
    "             #se não houver próxima página, o programa grava em um csv e salva em df    \n",
    "            if 'next_page_token' not in jj:\n",
    "                labels = ['Place Name','ID_Field', 'Latitude', 'Longitude', 'Rating', 'Tags']\n",
    "                location_df = pd.DataFrame.from_records(final_data, columns=labels)\n",
    "                location_df.to_csv('location.csv')\n",
    "                break\n",
    "            else:\n",
    "                next_page_token = jj['next_page_token']\n",
    "                search_url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json?key='+str(api_key)+'&pagetoken='+str(next_page_token)\n",
    "\n",
    "        return(final_data, location_df)\n",
    "\n",
    "    def find_details(final_data, api_key):\n",
    "\n",
    "        final_detailed_data =[]\n",
    "\n",
    "        #Usa o ID exclusivo de cada local para usar outra solicitação de API para obter informações de telefone e site de cada empresa.\n",
    "        for places in final_data:\n",
    "            id_field = places[1]\n",
    "            req_url = 'https://maps.googleapis.com/maps/api/place/details/json?place_id='+str(id_field)+'&fields=name,formatted_phone_number,website&key='+str(api_key)\n",
    "            respon = requests.get(req_url)\n",
    "            jj = json.loads(respon.text)\n",
    "            print(jj)\n",
    "            results = jj['result']\n",
    "            identification = id_field\n",
    "            try:\n",
    "                phone = results[\"formatted_phone_number\"]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            try:\n",
    "                website = results[\"website\"]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            title = results[\"name\"]\n",
    "            detailed_data = [title, identification, phone, website]\n",
    "            final_detailed_data.append(detailed_data)\n",
    "\n",
    "        columns = [\"Business\", \"ID_Field\",\"Phone\", \"Website\"]\n",
    "        details_df = pd.DataFrame.from_records(final_detailed_data, columns=columns)\n",
    "        details_df.to_csv('further_details.csv')\n",
    "        \n",
    "        return details_df\n",
    "\n",
    "    def join_data(details_df,location_df):\n",
    "\n",
    "        final_sheet = location_df.join(details_df.set_index('ID_Field'), on='ID_Field')\n",
    "\n",
    "        final_sheet.to_csv(str(keyword) + \".csv\")\n",
    "\n",
    "        print(final_sheet)\n",
    "\n",
    "        return final_sheet\n",
    "\n",
    "        \n",
    "    def main():\n",
    "        #assigning Parâmetros para pesquisa de localização\n",
    "        api_key = 'AIzaSyBBnqihmtHiPEWREzUzFEiAd0yhkjtvsGo' #AQUI api do google maps \n",
    "        search_radius = '100000'\n",
    "        \n",
    "        coords = '-26.996527444438925, -48.62762931857461' # AQUI vc tem que colocar as cordenadas do lugar onde quer pesquisar\n",
    "        request_url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json?location='+coords+'&radius='+str(search_radius)+'&keyword='+str(keyword)+'&key='+str(api_key)\n",
    "\n",
    "        #encontre os locais dos estabelecimentos desejados no google maps\n",
    "        final_data, location_df = find_locations(request_url, api_key)\n",
    "\n",
    "        #encontre site, telefone e avaliações de estabelecimentos\n",
    "        details_df = find_details(final_data, api_key)\n",
    "\n",
    "        #junte os dois dataframes para ter um produto final\n",
    "        non_spatial_data = join_data(details_df,location_df)\n",
    "\n",
    "        spatial_df = csv_to_point(non_spatial_data)\n",
    "\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLOCAR O LOCAL ONDE ESTÁ OS EXCELS SALVOS\n",
    "path = r'C:\\####\\###\\####\\###\\###'  \n",
    "\n",
    "# use compreensão de lista para criar uma lista de arquivos csv\n",
    "csv_files = [file for file in os.listdir(path) if file.endswith('.csv')]\n",
    "\n",
    "# cria uma lista vazia para armazenar os DataFrames\n",
    "df_list = []\n",
    "\n",
    "# iterar pelos arquivos csv\n",
    "for csv_file in csv_files:\n",
    "    # lê o arquivo csv atual em um DataFrame\n",
    "    df = pd.read_csv(os.path.join(path, csv_file))\n",
    "    # adiciona uma nova coluna 'file_name' com o nome do arquivo csv atual\n",
    "    df['name'] = os.path.basename(csv_file)\n",
    "    # anexa o DataFrame atual à lista\n",
    "    df_list.append(df)\n",
    "\n",
    "# concatenar todos os DataFrames em um único DataFrame\n",
    "merged_df = pd.concat(df_list)\n",
    "\n",
    "# grava o DataFrame mesclado em um novo arquivo csv\n",
    "merged_df.to_excel(\"all.xlsx\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contatos = pd.read_excel('all.xlsx')\n",
    "contatos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Envio de mensagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = '/####/###/####/chromedriver_win32/chromedriver.exe' #AQUI coloca onde está seu chromedriver\n",
    "\n",
    "navegador = webdriver.Chrome(driver_path)\n",
    "\n",
    "navegador.get(\"https://web.whatsapp.com/\") # abre o whatsapp web\n",
    "\n",
    "while len(navegador.find_elements(By.ID,\"side\")) < 1: # espera ate logar\n",
    "    time.sleep(1)\n",
    "\n",
    "# envia a mensagem \n",
    "for i, mensagem in enumerate(contatos['Mensagem']):\n",
    "    numero = contatos.loc[i,\"Phone\"]\n",
    "    nome = contatos.loc[i,\"Place Name\"]\n",
    "    texto = urllib.parse.quote(f\"Oi {nome}! {mensagem}\")\n",
    "    link = f\"https://web.whatsapp.com/send?phone={numero}&text={texto}\"\n",
    "    navegador.get(link)\n",
    "   \n",
    "    while len(navegador.find_elements(By.ID,\"side\")) < 1:\n",
    "        time.sleep(1)\n",
    "\n",
    "    navegador.find_element(By.XPATH,'//*[@id=\"main\"]/footer/div[1]/div/span[2]/div/div[2]/div[1]/div/div[1]/p').send_keys(Keys.ENTER)\n",
    "    time.sleep(10) # Aqui voce coloca o tempo de espera da mensagem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "665796ea3363072d3a6057ac2fdbe3c4fcb0d17a4b92295d9707f78e9c46c0af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
